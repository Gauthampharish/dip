{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='11.jpg'\n",
    "img = cv2.imread('11.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def color_balance(img):\n",
    "    # 1. Calculate the average intensity of each color channel\n",
    "    red_avg = np.mean(img[:,:,2])\n",
    "    green_avg = np.mean(img[:,:,1])\n",
    "    blue_avg = np.mean(img[:,:,0])\n",
    "\n",
    "    # 2. Compute the difference between the average intensity and the mean intensity\n",
    "    mean_intensity = np.mean([red_avg, green_avg, blue_avg])\n",
    "    red_diff = mean_intensity - red_avg\n",
    "    green_diff = mean_intensity - green_avg\n",
    "    blue_diff = mean_intensity - blue_avg\n",
    "\n",
    "    # 3. Adjust the intensity of each channel\n",
    "    img[:,:,2] = np.clip(img[:,:,2] + red_diff, 0, 255)\n",
    "    img[:,:,1] = np.clip(img[:,:,1] + green_diff, 0, 255)\n",
    "    img[:,:,0] = np.clip(img[:,:,0] + blue_diff, 0, 255)\n",
    "\n",
    "    # 4. Return the processed image\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "# Apply color balance\n",
    "balanced_img = color_balance(img)\n",
    "\n",
    "variable = name\n",
    "filename = f'balanced_{variable}.jpg'\n",
    "cv2.imwrite(filename, balanced_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Background Light for Each Channel: [56.   50.5  88.25]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def estimate_background_light_for_each_channel(image):\n",
    "    # Initialize background light for each channel\n",
    "    background_light_channels = np.zeros(3)\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray_image = image\n",
    "    \n",
    "    # Initialize threshold for quadtree division\n",
    "    threshold = gray_image.size * 0.001\n",
    "    \n",
    "    # Define function for quadtree division\n",
    "    def quadtree_division(image, threshold):\n",
    "        if image.size <=4:\n",
    "            return np.mean(image)\n",
    "        variance = np.var(image)\n",
    "        \n",
    "        # If variance is less than threshold, return mean intensity as background light\n",
    "        if variance < threshold:\n",
    "            return np.mean(image)\n",
    "        \n",
    "        # Otherwise, divide image into four quadrants\n",
    "        height, width = image.shape\n",
    "        half_height, half_width = height // 2, width // 2\n",
    "        quadrants = [\n",
    "            image[:half_height, :half_width],\n",
    "            image[:half_height, half_width:],\n",
    "            image[half_height:, :half_width],\n",
    "            image[half_height:, half_width:]\n",
    "        ]\n",
    "        \n",
    "        # Recursively call quadtree_division on each quadrant\n",
    "        background_lights = [quadtree_division(quadrant, threshold) for quadrant in quadrants]\n",
    "        \n",
    "        # Return the minimum background light among quadrants\n",
    "        return min(background_lights)\n",
    "    \n",
    "    # Start quadtree division for each channel\n",
    "    for i in range(3):  # Assuming BGR image\n",
    "        background_light_channels[i] = quadtree_division(image[:,:,i], threshold)\n",
    "    \n",
    "    return background_light_channels\n",
    "\n",
    "# Example usage:\n",
    "# Read RGB image\n",
    "new_name = f'balanced_{name}.jpg'\n",
    "image = cv2.imread(new_name)\n",
    "\n",
    "# Estimate background light for each channel\n",
    "background_light_channels = estimate_background_light_for_each_channel(image)\n",
    "print(\"Estimated Background Light for Each Channel:\", background_light_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_contrast_and_complex_performance_index(I, t):\n",
    "    \n",
    "    # Calculate the number of channels\n",
    "    num_channels = I.shape[2]\n",
    "    \n",
    "    # Initialize arrays to store contrast values Ci for each channel\n",
    "    Ci = np.zeros(num_channels)\n",
    "    \n",
    "    # Loop through each color channel\n",
    "    for i in range(num_channels):\n",
    "       \n",
    "        # Calculate the contrast value Ci for the current channel\n",
    "        squared_diff_channel = (I[:,:,i] - np.mean(I[:,:,i])) ** 2\n",
    "        Ci[i] = np.sum(squared_diff_channel / (t ** 2 * I.size))\n",
    "    \n",
    "    # Calculate the complex contrast performance index Ec\n",
    "    Ec = -np.sum(Ci)\n",
    "    \n",
    "    return Ci, Ec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_information_loss_El(I, A, t):\n",
    "    # Initialize J(x) array\n",
    "    J = np.zeros_like(I)\n",
    "    \n",
    "    # Calculate J(x) using the restoration model equation for each channel\n",
    "    for i in range(3):  # Assuming RGB image\n",
    "\n",
    "        J[:,:,i] = (1 / t) * (I[:,:,i] - A[i]) + A[i]\n",
    "    \n",
    "    # Ensure J is within the allowable range (0 to 255)\n",
    "    J_clipped = np.clip(J, 0, 255)\n",
    "    \n",
    "    # Calculate information loss function El\n",
    "    El = 0\n",
    "    \n",
    "    # Loop through each color channel\n",
    "    for i in range(3):  # Assuming RGB image\n",
    "        # Calculate information loss for each pixel in the channel\n",
    "        loss_channel = (np.minimum(0, J_clipped[:,:,i])**2) + np.maximum(0, J_clipped[:,:,i] - 255)\n",
    "        \n",
    "        # Sum up the information loss for the channel\n",
    "        El += np.sum(loss_channel)\n",
    "    \n",
    "    return El\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.63 GiB for an array with shape (27500, 27500) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m initial_guess \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maround(np\u001b[38;5;241m.\u001b[39mclip(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m*\u001b[39mI\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;241m+\u001b[39m constant, constant,\u001b[38;5;241m1\u001b[39m), decimals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Optimize transmittance\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m t_optimal, Ec_optimal, El_optimal, E_optimal \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_transmittance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_L\u001b[49m\u001b[43m,\u001b[49m\u001b[43minitial_guess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimized Transmittance (t*):\u001b[39m\u001b[38;5;124m\"\u001b[39m, t_optimal)\n",
      "Cell \u001b[1;32mIn[58], line 34\u001b[0m, in \u001b[0;36moptimize_transmittance\u001b[1;34m(I, A, lambda_L, initial_guess)\u001b[0m\n\u001b[0;32m     31\u001b[0m initial_guess_flat \u001b[38;5;241m=\u001b[39m initial_guess\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Use scipy.optimize.minimize to find the optimal t\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_guess_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBFGS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Reshape the optimal t back into a 2D matrix\u001b[39;00m\n\u001b[0;32m     37\u001b[0m t_optimal \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mreshape(I\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[1;32mc:\\vit\\sem6\\dip\\challenging-60\\.venv\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:708\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    706\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_cg(fun, x0, args, jac, callback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 708\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_bfgs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton-cg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    711\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\vit\\sem6\\dip\\challenging-60\\.venv\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:1452\u001b[0m, in \u001b[0;36m_minimize_bfgs\u001b[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, xrtol, c1, c2, hess_inv0, **unknown_options)\u001b[0m\n\u001b[0;32m   1450\u001b[0m     A1 \u001b[38;5;241m=\u001b[39m I \u001b[38;5;241m-\u001b[39m sk[:, np\u001b[38;5;241m.\u001b[39mnewaxis] \u001b[38;5;241m*\u001b[39m yk[np\u001b[38;5;241m.\u001b[39mnewaxis, :] \u001b[38;5;241m*\u001b[39m rhok\n\u001b[0;32m   1451\u001b[0m     A2 \u001b[38;5;241m=\u001b[39m I \u001b[38;5;241m-\u001b[39m yk[:, np\u001b[38;5;241m.\u001b[39mnewaxis] \u001b[38;5;241m*\u001b[39m sk[np\u001b[38;5;241m.\u001b[39mnewaxis, :] \u001b[38;5;241m*\u001b[39m rhok\n\u001b[1;32m-> 1452\u001b[0m     Hk \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(A1, \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA2\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m+\u001b[39m (rhok \u001b[38;5;241m*\u001b[39m sk[:, np\u001b[38;5;241m.\u001b[39mnewaxis] \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m   1453\u001b[0m                                              sk[np\u001b[38;5;241m.\u001b[39mnewaxis, :])\n\u001b[0;32m   1455\u001b[0m fval \u001b[38;5;241m=\u001b[39m old_fval\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m warnflag \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.63 GiB for an array with shape (27500, 27500) and data type float64"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def combined_objective_function(Ec, El, lambda_L):\n",
    "    # Calculate the combined objective function\n",
    "    return Ec + lambda_L * El\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def optimize_transmittance(I, A, lambda_L, initial_guess):\n",
    "    # Define the objective function for scipy.optimize.minimize\n",
    "    def objective(t):\n",
    "        # Reshape t back into a 2D matrix\n",
    "        t = t.reshape(I.shape[:2])\n",
    "\n",
    "        # Calculate contrast value Ci and complex contrast performance index Ec\n",
    "        Ci, Ec = calculate_contrast_and_complex_performance_index(I, t)\n",
    "\n",
    "        # Calculate information loss El\n",
    "        El = calculate_information_loss_El(I, A, t)\n",
    "\n",
    "        # Calculate combined objective function E\n",
    "        E = combined_objective_function(Ec, El, lambda_L)\n",
    "\n",
    "        return E\n",
    "\n",
    "    # Flatten the initial guess into a 1D array\n",
    "    initial_guess_flat = initial_guess.flatten()\n",
    "\n",
    "    # Use scipy.optimize.minimize to find the optimal t\n",
    "    result = minimize(objective, initial_guess_flat, method='BFGS')\n",
    "\n",
    "    # Reshape the optimal t back into a 2D matrix\n",
    "    t_optimal = result.x.reshape(I.shape[:2])\n",
    "\n",
    "    # Calculate the optimal Ec, El, and E\n",
    "    Ci_optimal, Ec_optimal = calculate_contrast_and_complex_performance_index(I, t_optimal)\n",
    "    El_optimal = calculate_information_loss_El(I, A, t_optimal)\n",
    "    E_optimal = combined_objective_function(Ec_optimal, El_optimal, lambda_L)\n",
    "\n",
    "    # Return the best results\n",
    "    return t_optimal, Ec_optimal, El_optimal, E_optimal\n",
    "\n",
    "# Example usage:\n",
    "# Read RGB image\n",
    "I = cv2.imread(new_name)\n",
    "\n",
    "# Background light A obtained from Step 1 (assuming some value)\n",
    "A = background_light_channels\n",
    "\n",
    "# Tradeoff factor\n",
    "lambda_L = 5\n",
    "\n",
    "# Initial guesses for transmittance\n",
    "# Initial guess for transmittance\n",
    "constant = 0.1  # or any small value you prefer\n",
    "initial_guess = np.around(np.clip(np.random.rand(*I.shape[:2]) + constant, constant,1), decimals=4)\n",
    "\n",
    "# Optimize transmittance\n",
    "t_optimal, Ec_optimal, El_optimal, E_optimal = optimize_transmittance(I, A, lambda_L,initial_guess)\n",
    "\n",
    "# Print the results\n",
    "print(\"Optimized Transmittance (t*):\", t_optimal)\n",
    "print(\"Optimal Ec:\", Ec_optimal)\n",
    "print(\"Optimal El:\", El_optimal)\n",
    "print(\"Optimal E:\", E_optimal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def restore_image(I, A, t):\n",
    "    # Initialize the restored image\n",
    "    restored_image = np.zeros_like(I)\n",
    "\n",
    "    # Iterate over each pixel in the image\n",
    "    for i in range(I.shape[0]):\n",
    "        for j in range(I.shape[1]):\n",
    "            # Apply the restoration model formula for each channel\n",
    "            for k in range(3):  # Iterate over R, G, B channels\n",
    "                restored_image[i, j, k] = (1 / t[i, j]) * (I[i, j, k] - A[k]) + A[k]\n",
    "\n",
    "    return restored_image\n",
    "\n",
    "# Example usage:\n",
    "# Read RGB image\n",
    "I = cv2.imread(new_name)\n",
    "\n",
    "# Assuming background light A is already obtained\n",
    "A = background_light_channels # Example background light (for each channel)\n",
    "\n",
    "\n",
    "# Restore the image using the restoration model and the calculated transmittance map\n",
    "\n",
    "restored_image = restore_image(I, A, t_optimal)\n",
    "restored_name=f'restored_{name}.jpg'\n",
    "cv2.imwrite(restored_name, restored_image)\n",
    "# Display or save the restored image\n",
    "cv2.imshow('Restored Image', restored_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Red Channel Value: 109.21555\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_average_red_channel_value(image):\n",
    "    # Assuming 'image' is a 3D NumPy array representing the image (height x width x channels)\n",
    "    red_channel = image[:, :, 0]  # Assuming red channel is the first channel (index 0)\n",
    "    average_red_value = np.mean(red_channel)\n",
    "    return average_red_value\n",
    "\n",
    "average_red = calculate_average_red_channel_value(restored_image)\n",
    "print(\"Average Red Channel Value:\", average_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n",
      "Histogram Threshold: 138.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_histogram_threshold(image):\n",
    "    # Calculate total number of pixels\n",
    "    height, width, _ = image.shape\n",
    "    total_pixels = height * width\n",
    "    print(total_pixels)\n",
    "    # Calculate histogram threshold (h1) as n*0.225%\n",
    "    histogram_threshold = total_pixels * 0.00115\n",
    "    \n",
    "    return  histogram_threshold\n",
    "\n",
    "histogram_threshold = calculate_histogram_threshold(restored_image)\n",
    "print(\"Histogram Threshold:\", histogram_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "r_threshold = 0\n",
    "\n",
    "def histogram_stretching(image, R_ave, R_threshold):\n",
    "    # Calculate total number of pixels\n",
    "    height, width, _ = image.shape\n",
    "    total_pixels = height * width\n",
    "    \n",
    "    # Determine if attenuation of red light is slight or heavy\n",
    "    if R_ave >= R_threshold:  # Slight attenuation\n",
    "        channels = [0, 1, 2]  # Stretching for all channels (R, G, B)\n",
    "    else:  # Heavy attenuation\n",
    "        channels = [1, 2]  # Stretching for G, B channels only\n",
    "    \n",
    "    # Calculate satisfactory threshold ht as n * 0.225%\n",
    "    ht = total_pixels * 0.00225\n",
    "    \n",
    "    # Calculate minimal and maximal scalar values based on ht\n",
    "    imin = 0\n",
    "    imax = 255\n",
    "    \n",
    "    # If ht is provided and it's greater than zero, update imin and imax\n",
    "    if ht > 0:\n",
    "        # Calculate lower and upper thresholds based on ht\n",
    "        imin = np.min(image)\n",
    "        imax = np.max(image)\n",
    "        lower_threshold_count = int(ht)\n",
    "        upper_threshold_count = int(total_pixels - ht)\n",
    "        sorted_pixels = np.sort(image.flatten())\n",
    "        imin = sorted_pixels[lower_threshold_count]\n",
    "        imax = sorted_pixels[upper_threshold_count]\n",
    "\n",
    "    # Apply histogram stretching to selected channels\n",
    "    stretched_image = image.copy()\n",
    "    for channel in channels:\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                old_value = stretched_image[i, j, channel]\n",
    "                if old_value < imin:\n",
    "                    stretched_image[i, j, channel] = 0\n",
    "                elif old_value > imax:\n",
    "                    stretched_image[i, j, channel] = 255\n",
    "                else:\n",
    "                    stretched_image[i, j, channel] = 255 * (old_value - imin) / (imax - imin)\n",
    "    \n",
    "    return stretched_image\n",
    "\n",
    "# Example usage:\n",
    "stretched_image_model = histogram_stretching(restored_image, average_red, r_threshold)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streched_name=f'stretched_{name}.jpg'\n",
    "cv2.imwrite(streched_name, stretched_image_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage import color\n",
    "\n",
    "def calculate_rms_contrast(image):\n",
    "    \"\"\"\n",
    "    Calculate the Root Mean Square (RMS) contrast of an image.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean(np.square(image - np.mean(image))))\n",
    "\n",
    "def calculate_uciqe(image):\n",
    "    \"\"\"\n",
    "    Calculate the Underwater Color Image Quality Evaluation (UCIQE) of an image.\n",
    "    \"\"\"\n",
    "    c1 = 0.4680\n",
    "    c2 = 0.2745\n",
    "    c3 = 0.2576\n",
    "    img_yuv = color.rgb2yuv(image)\n",
    "    y = img_yuv[:,:,0]\n",
    "    u = img_yuv[:,:,1]\n",
    "    v = img_yuv[:,:,2]\n",
    "    uciqe = c1 * np.std(y) / np.mean(y) + c2 * np.cov(u, v) / (np.std(u) * np.std(v)) + c3 * np.mean(v)\n",
    "    return uciqe\n",
    "\n",
    "def calculate_psnr(image_true, image_test):\n",
    "    \"\"\"\n",
    "    Calculate the Peak Signal-to-Noise Ratio (PSNR) between two images.\n",
    "    \"\"\"\n",
    "    return psnr(image_true, image_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS contrast of image 1: 15.576318265089562\n",
      "RMS contrast of image 2: 44.177682355259584\n",
      "UCIQE of image 1: [[0.24534417 0.24535076 0.24419867 ... 0.10883901 0.10980822 0.10996243]\n",
      " [0.24535076 0.2453794  0.24422585 ... 0.10888598 0.10985345 0.11000683]\n",
      " [0.24419867 0.24422585 0.24330792 ... 0.10905831 0.11003872 0.11017365]\n",
      " ...\n",
      " [0.10883901 0.10888598 0.10905831 ... 0.09381207 0.09287067 0.09304693]\n",
      " [0.10980822 0.10985345 0.11003872 ... 0.09287067 0.09428684 0.09445564]\n",
      " [0.10996243 0.11000683 0.11017365 ... 0.09304693 0.09445564 0.09474101]]\n",
      "UCIQE of image 2: [[0.28078693 0.13873432 0.13761515 ... 0.13363631 0.12608118 0.09595774]\n",
      " [0.13873432 0.30969605 0.14814454 ... 0.12780133 0.11453609 0.11636461]\n",
      " [0.13761515 0.14814454 0.22522155 ... 0.14646533 0.12093957 0.11049589]\n",
      " ...\n",
      " [0.13363631 0.12780133 0.14646533 ... 0.43069363 0.14025583 0.11586494]\n",
      " [0.12608118 0.11453609 0.12093957 ... 0.14025583 0.5266953  0.12699541]\n",
      " [0.09595774 0.11636461 0.11049589 ... 0.11586494 0.12699541 0.51003115]]\n",
      "PSNR between image 1 and image 2: 5.598958542513196\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m     ssim_value \u001b[38;5;241m=\u001b[39m calculate_ssim(image1, image2)\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSIM between image 1 and image 2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mssim_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m \u001b[43mfuu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstretched_image_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[47], line 22\u001b[0m, in \u001b[0;36mfuu\u001b[1;34m(image1, image2)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPSNR between image 1 and image 2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpsnr_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Calculate SSIM\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m ssim_value \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_ssim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSIM between image 1 and image 2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mssim_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[41], line 45\u001b[0m, in \u001b[0;36mcalculate_ssim\u001b[1;34m(image_true, image_test)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# If window size is less than 7, set it to the minimum valid value of 7\u001b[39;00m\n\u001b[0;32m     43\u001b[0m win_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(win_size, \u001b[38;5;241m7\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultichannel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\vit\\sem6\\dip\\challenging-60\\.venv\\Lib\\site-packages\\skimage\\metrics\\_structural_similarity.py:186\u001b[0m, in \u001b[0;36mstructural_similarity\u001b[1;34m(im1, im2, win_size, gradient, data_range, channel_axis, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m         win_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m  \u001b[38;5;66;03m# backwards compatibility\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many((np\u001b[38;5;241m.\u001b[39masarray(im1\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m-\u001b[39m win_size) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwin_size exceeds image extent. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEither ensure that your images are \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat least 7x7; or pass win_size explicitly \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min the function call, with an odd value \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mless than or equal to the smaller side of your \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages. If your images are multichannel \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(with color channels), set channel_axis to \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe axis number corresponding to the channels.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    195\u001b[0m     )\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (win_size \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWindow size must be odd.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels."
     ]
    }
   ],
   "source": [
    "def fuu(image1, image2):\n",
    "    \"\"\"\n",
    "    Main function to calculate image quality metrics.\n",
    "    \"\"\"\n",
    "    # Calculate RMS contrast\n",
    "    rms_contrast1 = calculate_rms_contrast(image1)\n",
    "    rms_contrast2 = calculate_rms_contrast(image2)\n",
    "    print(f\"RMS contrast of image 1: {rms_contrast1}\")\n",
    "    print(f\"RMS contrast of image 2: {rms_contrast2}\")\n",
    "\n",
    "    # Calculate UCIQE\n",
    "    uciqe1 = calculate_uciqe(image1)\n",
    "    uciqe2 = calculate_uciqe(image2)\n",
    "    print(f\"UCIQE of image 1: {uciqe1}\")\n",
    "    print(f\"UCIQE of image 2: {uciqe2}\")\n",
    "\n",
    "    # Calculate PSNR\n",
    "    psnr_value = calculate_psnr(image1, image2)\n",
    "    print(f\"PSNR between image 1 and image 2: {psnr_value}\")\n",
    "\n",
    "   \n",
    "\n",
    "fuu(img, stretched_image_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
