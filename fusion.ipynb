{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('bg_11.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def color_balance(img):\n",
    "    # 1. Calculate the average intensity of each color channel\n",
    "    red_avg = np.mean(img[:,:,2])\n",
    "    green_avg = np.mean(img[:,:,1])\n",
    "    blue_avg = np.mean(img[:,:,0])\n",
    "\n",
    "    # 2. Compute the difference between the average intensity and the mean intensity\n",
    "    mean_intensity = np.mean([red_avg, green_avg, blue_avg])\n",
    "    red_diff = mean_intensity - red_avg\n",
    "    green_diff = mean_intensity - green_avg\n",
    "    blue_diff = mean_intensity - blue_avg\n",
    "\n",
    "    # 3. Adjust the intensity of each channel\n",
    "    img[:,:,2] = np.clip(img[:,:,2] + red_diff, 0, 255)\n",
    "    img[:,:,1] = np.clip(img[:,:,1] + green_diff, 0, 255)\n",
    "    img[:,:,0] = np.clip(img[:,:,0] + blue_diff, 0, 255)\n",
    "\n",
    "    # 4. Return the processed image\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "# Apply color balance\n",
    "balanced_img = color_balance(img)\n",
    "\n",
    "# Save the result\n",
    "cv2.imwrite('balanced.jpg', balanced_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Background Light for Each Channel: [107.00965833 106.2381     106.08169167]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def estimate_background_light_for_each_channel(image):\n",
    "    # Initialize background light for each channel\n",
    "    background_light_channels = np.zeros(3)\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray_image = image\n",
    "    \n",
    "    # Initialize threshold for quadtree division\n",
    "    threshold = gray_image.size * 0.001\n",
    "    \n",
    "    # Define function for quadtree division\n",
    "    def quadtree_division(image, threshold):\n",
    "        variance = np.var(image)\n",
    "        \n",
    "        # If variance is less than threshold, return mean intensity as background light\n",
    "        if variance < threshold:\n",
    "            return np.mean(image)\n",
    "        \n",
    "        # Otherwise, divide image into four quadrants\n",
    "        height, width = image.shape\n",
    "        half_height, half_width = height // 2, width // 2\n",
    "        quadrants = [\n",
    "            image[:half_height, :half_width],\n",
    "            image[:half_height, half_width:],\n",
    "            image[half_height:, :half_width],\n",
    "            image[half_height:, half_width:]\n",
    "        ]\n",
    "        \n",
    "        # Recursively call quadtree_division on each quadrant\n",
    "        background_lights = [quadtree_division(quadrant, threshold) for quadrant in quadrants]\n",
    "        \n",
    "        # Return the minimum background light among quadrants\n",
    "        return min(background_lights)\n",
    "    \n",
    "    # Start quadtree division for each channel\n",
    "    for i in range(3):  # Assuming BGR image\n",
    "        background_light_channels[i] = quadtree_division(image[:,:,i], threshold)\n",
    "    \n",
    "    return background_light_channels\n",
    "\n",
    "# Example usage:\n",
    "# Read RGB image\n",
    "image = cv2.imread('balanced.jpg')\n",
    "\n",
    "# Estimate background light for each channel\n",
    "background_light_channels = estimate_background_light_for_each_channel(image)\n",
    "print(\"Estimated Background Light for Each Channel:\", background_light_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_contrast_and_complex_performance_index(I, t):\n",
    "    \n",
    "    # Calculate the number of channels\n",
    "    num_channels = I.shape[2]\n",
    "    \n",
    "    # Initialize arrays to store contrast values Ci for each channel\n",
    "    Ci = np.zeros(num_channels)\n",
    "    \n",
    "    # Loop through each color channel\n",
    "    for i in range(num_channels):\n",
    "       \n",
    "        # Calculate the contrast value Ci for the current channel\n",
    "        squared_diff_channel = (I[:,:,i] - np.mean(I[:,:,i])) ** 2\n",
    "        Ci[i] = np.sum(squared_diff_channel / (t ** 2 * I.size))\n",
    "    \n",
    "    # Calculate the complex contrast performance index Ec\n",
    "    Ec = -np.sum(Ci)\n",
    "    \n",
    "    return Ci, Ec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_information_loss_El(I, A, t):\n",
    "    # Initialize J(x) array\n",
    "    J = np.zeros_like(I)\n",
    "    \n",
    "    # Calculate J(x) using the restoration model equation for each channel\n",
    "    for i in range(3):  # Assuming RGB image\n",
    "\n",
    "        J[:,:,i] = (1 / t) * (I[:,:,i] - A[i]) + A[i]\n",
    "    \n",
    "    # Ensure J is within the allowable range (0 to 255)\n",
    "    J_clipped = np.clip(J, 0, 255)\n",
    "    \n",
    "    # Calculate information loss function El\n",
    "    El = 0\n",
    "    \n",
    "    # Loop through each color channel\n",
    "    for i in range(3):  # Assuming RGB image\n",
    "        # Calculate information loss for each pixel in the channel\n",
    "        loss_channel = (np.minimum(0, J_clipped[:,:,i])**2) + np.maximum(0, J_clipped[:,:,i] - 255)\n",
    "        \n",
    "        # Sum up the information loss for the channel\n",
    "        El += np.sum(loss_channel)\n",
    "    \n",
    "    return El\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 kk\n",
      "Optimized Transmittance (t*): [[0.3141 0.2741 1.     ... 0.5924 0.8642 0.4519]\n",
      " [0.4508 0.8776 1.     ... 0.1472 0.7002 1.    ]\n",
      " [0.8963 0.189  1.     ... 0.2474 0.5361 0.759 ]\n",
      " ...\n",
      " [0.8265 0.8611 0.7942 ... 0.2458 1.     0.6034]\n",
      " [0.6616 0.9934 0.7592 ... 0.8511 0.3587 1.    ]\n",
      " [1.     0.7182 0.4092 ... 0.1923 1.     0.8179]]\n",
      "Optimal Ec: -2186.725305872255\n",
      "Optimal El: 39321033\n",
      "Optimal E: 196602978.27469411\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def combined_objective_function(Ec, El, lambda_L):\n",
    "    # Calculate the combined objective function\n",
    "    return Ec + lambda_L * El\n",
    "\n",
    "def optimize_transmittance(I, A, lambda_L, initial_guesses):\n",
    "    # Initialize lists to store results\n",
    "    optimal_t = []\n",
    "    optimal_Ec = []\n",
    "    optimal_El = []\n",
    "    optimal_E = []\n",
    "    print(len(initial_guesses),\"kk\")\n",
    "    # Loop through each initial guess for t\n",
    "    for i, initial_guess in enumerate(initial_guesses):\n",
    "       \n",
    "\n",
    "       \n",
    "            # Calculate contrast value Ci and complex contrast performance index Ec\n",
    "        Ci, Ec = calculate_contrast_and_complex_performance_index(I, initial_guess)\n",
    "    \n",
    "            # Calculate information loss El\n",
    "        El = calculate_information_loss_El(I, A, initial_guess)\n",
    "            \n",
    "            # Calculate combined objective function E\n",
    "        E = combined_objective_function(Ec, El, lambda_L)\n",
    "            \n",
    "            # Store results\n",
    "        \n",
    "                \n",
    "        \n",
    "        \n",
    "        # Store the results for this initial guess\n",
    "        optimal_t.append(initial_guess)\n",
    "        optimal_Ec.append(Ec)\n",
    "        optimal_El.append(El)\n",
    "        optimal_E.append(E)\n",
    "    \n",
    "    # Find the index corresponding to the minimum value of E among all initial guesses\n",
    "    best_index = np.argmin(optimal_E)\n",
    "    \n",
    "    # Return the best results\n",
    "    return optimal_t[best_index], optimal_Ec[best_index], optimal_El[best_index], optimal_E[best_index]\n",
    "\n",
    "# Example usage:\n",
    "# Read RGB image\n",
    "I = cv2.imread('balanced.jpg')\n",
    "\n",
    "# Background light A obtained from Step 1 (assuming some value)\n",
    "A = background_light_channels\n",
    "\n",
    "# Tradeoff factor\n",
    "lambda_L = 5\n",
    "\n",
    "# Initial guesses for transmittance\n",
    "constant = 0.1  # or any small value you prefer\n",
    "initial_guesses = [np.around(np.clip(np.random.rand(*I.shape[:2]) + constant, constant,1), decimals=4) for _ in range(1000)]\n",
    "\n",
    "# Optimize transmittance\n",
    "t_optimal, Ec_optimal, El_optimal, E_optimal = optimize_transmittance(I, A, lambda_L,initial_guesses )\n",
    "\n",
    "# Print the results\n",
    "print(\"Optimized Transmittance (t*):\", t_optimal)\n",
    "print(\"Optimal Ec:\", Ec_optimal)\n",
    "print(\"Optimal El:\", El_optimal)\n",
    "print(\"Optimal E:\", E_optimal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def restore_image(I, A, t):\n",
    "    # Initialize the restored image\n",
    "    restored_image = np.zeros_like(I)\n",
    "\n",
    "    # Iterate over each pixel in the image\n",
    "    for i in range(I.shape[0]):\n",
    "        for j in range(I.shape[1]):\n",
    "            # Apply the restoration model formula for each channel\n",
    "            for k in range(3):  # Iterate over R, G, B channels\n",
    "                restored_image[i, j, k] = (1 / t[i, j]) * (I[i, j, k] - A[k]) + A[k]\n",
    "\n",
    "    return restored_image\n",
    "\n",
    "# Example usage:\n",
    "# Read RGB image\n",
    "I = cv2.imread('balanced.jpg')\n",
    "\n",
    "# Assuming background light A is already obtained\n",
    "A = background_light_channels # Example background light (for each channel)\n",
    "\n",
    "\n",
    "# Restore the image using the restoration model and the calculated transmittance map\n",
    "restored_image = restore_image(I, A, t_optimal)\n",
    "cv2.imwrite('restored_image_model.jpg', restored_image)\n",
    "# Display or save the restored image\n",
    "cv2.imshow('Restored Image', restored_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[240 229  99]\n",
      "  [  4 247  98]\n",
      "  [149 145 104]\n",
      "  ...\n",
      "  [191 173  68]\n",
      "  [164 152  80]\n",
      "  [217 194  57]]\n",
      "\n",
      " [[200 192 101]\n",
      "  [154 150 103]\n",
      "  [149 145 104]\n",
      "  ...\n",
      "  [190 120 213]\n",
      "  [178 163  74]\n",
      "  [157 146  84]]\n",
      "\n",
      " [[153 149 103]\n",
      "  [ 73  55  95]\n",
      "  [149 145 104]\n",
      "  ...\n",
      "  [ 53  10  16]\n",
      "  [200 180  64]\n",
      "  [172 158  76]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[109 121 142]\n",
      "  [109 121 140]\n",
      "  [109 122 143]\n",
      "  ...\n",
      "  [ 41  93 117]\n",
      "  [ 90 102 108]\n",
      "  [ 77  97 107]]\n",
      "\n",
      " [[ 99 119 143]\n",
      "  [102 116 132]\n",
      "  [103 120 141]\n",
      "  ...\n",
      "  [ 91 105 113]\n",
      "  [ 67 102 119]\n",
      "  [ 92 104 110]]\n",
      "\n",
      " [[100 113 129]\n",
      "  [ 97 115 137]\n",
      "  [ 94 127 166]\n",
      "  ...\n",
      "  [ 44 110 142]\n",
      "  [ 93 105 111]\n",
      "  [ 89 104 112]]]\n"
     ]
    }
   ],
   "source": [
    "print(restored_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2;\n",
    "import math;\n",
    "import numpy as np;\n",
    "\n",
    "def DarkChannel(im,sz):\n",
    "    b,g,r = cv2.split(im)\n",
    "    dc = cv2.min(cv2.min(r,g),b);\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(sz,sz))\n",
    "    dark = cv2.erode(dc,kernel)\n",
    "    return dark\n",
    "\n",
    "def AtmLight(im,dark):\n",
    "    [h,w] = im.shape[:2]\n",
    "    imsz = h*w\n",
    "    numpx = int(max(math.floor(imsz/1000),1))\n",
    "    darkvec = dark.reshape(imsz);\n",
    "    imvec = im.reshape(imsz,3);\n",
    "\n",
    "    indices = darkvec.argsort();\n",
    "    indices = indices[imsz-numpx::]\n",
    "\n",
    "    atmsum = np.zeros([1,3])\n",
    "    for ind in range(1,numpx):\n",
    "       atmsum = atmsum + imvec[indices[ind]]\n",
    "\n",
    "    A = atmsum / numpx;\n",
    "    return A\n",
    "\n",
    "def TransmissionEstimate(im,A,sz):\n",
    "    omega = 0.95;\n",
    "    im3 = np.empty(im.shape,im.dtype);\n",
    "\n",
    "    for ind in range(0,3):\n",
    "        im3[:,:,ind] = im[:,:,ind]/A[0,ind]\n",
    "\n",
    "    transmission = 1 - omega*DarkChannel(im3,sz);\n",
    "    return transmission\n",
    "\n",
    "def Guidedfilter(im,p,r,eps):\n",
    "    mean_I = cv2.boxFilter(im,cv2.CV_64F,(r,r));\n",
    "    mean_p = cv2.boxFilter(p, cv2.CV_64F,(r,r));\n",
    "    mean_Ip = cv2.boxFilter(im*p,cv2.CV_64F,(r,r));\n",
    "    cov_Ip = mean_Ip - mean_I*mean_p;\n",
    "\n",
    "    mean_II = cv2.boxFilter(im*im,cv2.CV_64F,(r,r));\n",
    "    var_I   = mean_II - mean_I*mean_I;\n",
    "\n",
    "    a = cov_Ip/(var_I + eps);\n",
    "    b = mean_p - a*mean_I;\n",
    "\n",
    "    mean_a = cv2.boxFilter(a,cv2.CV_64F,(r,r));\n",
    "    mean_b = cv2.boxFilter(b,cv2.CV_64F,(r,r));\n",
    "\n",
    "    q = mean_a*im + mean_b;\n",
    "    return q;\n",
    "\n",
    "def TransmissionRefine(im,et):\n",
    "    gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY);\n",
    "    gray = np.float64(gray)/255;\n",
    "    r = 60;\n",
    "    eps = 0.0001;\n",
    "    t = Guidedfilter(gray,et,r,eps);\n",
    "\n",
    "    return t;\n",
    "\n",
    "def Recover(im,t,A,tx = 0.1):\n",
    "    res = np.empty(im.shape,im.dtype);\n",
    "    t = cv2.max(t,tx);\n",
    "\n",
    "    for ind in range(0,3):\n",
    "        res[:,:,ind] = (im[:,:,ind]-A[0,ind])/t + A[0,ind]\n",
    "\n",
    "    return res\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import sys\n",
    "    try:\n",
    "        fn = sys.argv[1]\n",
    "    except:\n",
    "        fn = './image/15.png'\n",
    "\n",
    "    def nothing(*argv):\n",
    "        pass\n",
    "\n",
    "    src = cv2.imread(\"balanced.jpg\");\n",
    "\n",
    "    I = src.astype('float64')/255;\n",
    " \n",
    "    dark = DarkChannel(I,15);\n",
    "    A = AtmLight(I,dark);\n",
    "    te = TransmissionEstimate(I,A,15);\n",
    "    t = TransmissionRefine(src,te);\n",
    "    dcb = Recover(I,t,A,0.1);\n",
    "\n",
    "  \n",
    "    cv2.imshow('dcb',dcb);\n",
    "    cv2.imwrite(\"dcbimage.png\",J*255);\n",
    "    cv2.waitKey();\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def denormalize_image(image):\n",
    "    # Denormalize image from range [0, 1] to [0, 255]\n",
    "    image = image * 255\n",
    "\n",
    "    # Convert image to uint8\n",
    "    image = image.astype(np.uint8)\n",
    "\n",
    "    return image\n",
    "dcb=denormalize_image(dcb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Red Channel Value: 82.602475\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_average_red_channel_value(image):\n",
    "    # Assuming 'image' is a 3D NumPy array representing the image (height x width x channels)\n",
    "    red_channel = image[:, :, 0]  # Assuming red channel is the first channel (index 0)\n",
    "    average_red_value = np.mean(red_channel)\n",
    "    return average_red_value\n",
    "\n",
    "average_red = calculate_average_red_channel_value(dcb)\n",
    "print(\"Average Red Channel Value:\", average_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Red Channel Value: 109.365625\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_average_red_channel_value(image):\n",
    "    # Assuming 'image' is a 3D NumPy array representing the image (height x width x channels)\n",
    "    red_channel = image[:, :, 0]  # Assuming red channel is the first channel (index 0)\n",
    "    average_red_value = np.mean(red_channel)\n",
    "    return average_red_value\n",
    "\n",
    "average_red = calculate_average_red_channel_value(restored_image)\n",
    "print(\"Average Red Channel Value:\", average_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n",
      "Histogram Threshold: 270.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_histogram_threshold(image):\n",
    "    # Calculate total number of pixels\n",
    "    height, width, _ = image.shape\n",
    "    total_pixels = height * width\n",
    "    print(total_pixels)\n",
    "    # Calculate histogram threshold (h1) as n*0.225%\n",
    "    histogram_threshold = total_pixels * 0.00225\n",
    "    \n",
    "    return  histogram_threshold\n",
    "\n",
    "histogram_threshold = calculate_histogram_threshold(restored_image)\n",
    "print(\"Histogram Threshold:\", histogram_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n",
      "Histogram Threshold: 270.0\n"
     ]
    }
   ],
   "source": [
    "r_threshold = 107\n",
    "def calculate_histogram_threshold(image):\n",
    "    # Calculate total number of pixels\n",
    "    height, width, _ = image.shape\n",
    "    total_pixels = height * width\n",
    "    print(total_pixels)\n",
    "    # Calculate histogram threshold (h1) as n*0.225%\n",
    "    histogram_threshold = total_pixels * 0.00225\n",
    "    \n",
    "    return  histogram_threshold\n",
    "\n",
    "histogram_threshold = calculate_histogram_threshold(J)\n",
    "print(\"Histogram Threshold:\", histogram_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def histogram_stretching(image, R_ave, R_threshold):\n",
    "    # Calculate total number of pixels\n",
    "    height, width, _ = image.shape\n",
    "    total_pixels = height * width\n",
    "    \n",
    "    # Determine if attenuation of red light is slight or heavy\n",
    "    if R_ave >= R_threshold:  # Slight attenuation\n",
    "        channels = [0, 1, 2]  # Stretching for all channels (R, G, B)\n",
    "    else:  # Heavy attenuation\n",
    "        channels = [1, 2]  # Stretching for G, B channels only\n",
    "    \n",
    "    # Calculate satisfactory threshold ht as n * 0.225%\n",
    "    ht = total_pixels * 0.00225\n",
    "    \n",
    "    # Calculate minimal and maximal scalar values based on ht\n",
    "    imin = 0\n",
    "    imax = 255\n",
    "    \n",
    "    # If ht is provided and it's greater than zero, update imin and imax\n",
    "    if ht > 0:\n",
    "        # Calculate lower and upper thresholds based on ht\n",
    "        imin = np.min(image)\n",
    "        imax = np.max(image)\n",
    "        lower_threshold_count = int(ht)\n",
    "        upper_threshold_count = int(total_pixels - ht)\n",
    "        sorted_pixels = np.sort(image.flatten())\n",
    "        imin = sorted_pixels[lower_threshold_count]\n",
    "        imax = sorted_pixels[upper_threshold_count]\n",
    "\n",
    "    # Apply histogram stretching to selected channels\n",
    "    stretched_image = image.copy()\n",
    "    for channel in channels:\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                old_value = stretched_image[i, j, channel]\n",
    "                if old_value < imin:\n",
    "                    stretched_image[i, j, channel] = 0\n",
    "                elif old_value > imax:\n",
    "                    stretched_image[i, j, channel] = 255\n",
    "                else:\n",
    "                    stretched_image[i, j, channel] = 255 * (old_value - imin) / (imax - imin)\n",
    "    \n",
    "    return stretched_image\n",
    "\n",
    "# Example usage:\n",
    "stretched_image = histogram_stretching(J, average_red, r_threshold)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def histogram_stretching(image, R_ave, R_threshold):\n",
    "    # Calculate total number of pixels\n",
    "    height, width, _ = image.shape\n",
    "    total_pixels = height * width\n",
    "    \n",
    "    # Determine if attenuation of red light is slight or heavy\n",
    "    if R_ave >= R_threshold:  # Slight attenuation\n",
    "        channels = [0, 1, 2]  # Stretching for all channels (R, G, B)\n",
    "    else:  # Heavy attenuation\n",
    "        channels = [1, 2]  # Stretching for G, B channels only\n",
    "    \n",
    "    # Calculate satisfactory threshold ht as n * 0.225%\n",
    "    ht = total_pixels * 0.00225\n",
    "    \n",
    "    # Calculate minimal and maximal scalar values based on ht\n",
    "    imin = 0\n",
    "    imax = 255\n",
    "    \n",
    "    # If ht is provided and it's greater than zero, update imin and imax\n",
    "    if ht > 0:\n",
    "        # Calculate lower and upper thresholds based on ht\n",
    "        imin = np.min(image)\n",
    "        imax = np.max(image)\n",
    "        lower_threshold_count = int(ht)\n",
    "        upper_threshold_count = int(total_pixels - ht)\n",
    "        sorted_pixels = np.sort(image.flatten())\n",
    "        imin = sorted_pixels[lower_threshold_count]\n",
    "        imax = sorted_pixels[upper_threshold_count]\n",
    "\n",
    "    # Apply histogram stretching to selected channels\n",
    "    stretched_image = image.copy()\n",
    "    for channel in channels:\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                old_value = stretched_image[i, j, channel]\n",
    "                if old_value < imin:\n",
    "                    stretched_image[i, j, channel] = 0\n",
    "                elif old_value > imax:\n",
    "                    stretched_image[i, j, channel] = 255\n",
    "                else:\n",
    "                    stretched_image[i, j, channel] = 255 * (old_value - imin) / (imax - imin)\n",
    "    \n",
    "    return stretched_image\n",
    "\n",
    "# Example usage:\n",
    "stretched_image_model = histogram_stretching(restored_image, average_red, r_threshold)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('stretched_image.jpg', stretched_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('stretched_image_model.jpg', stretched_image_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
