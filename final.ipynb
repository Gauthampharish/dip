{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def color_balance(img,name):\n",
    "    # 1. Calculate the average intensity of each color channel\n",
    "    red_avg = np.mean(img[:,:,2])\n",
    "    green_avg = np.mean(img[:,:,1])\n",
    "    blue_avg = np.mean(img[:,:,0])\n",
    "\n",
    "    # 2. Compute the difference between the average intensity and the mean intensity\n",
    "    mean_intensity = np.mean([red_avg, green_avg, blue_avg])\n",
    "    red_diff = mean_intensity - red_avg\n",
    "    green_diff = mean_intensity - green_avg\n",
    "    blue_diff = mean_intensity - blue_avg\n",
    "\n",
    "    # 3. Adjust the intensity of each channel\n",
    "    img[:,:,2] = np.clip(img[:,:,2] + red_diff, 0, 255)\n",
    "    img[:,:,1] = np.clip(img[:,:,1] + green_diff, 0, 255)\n",
    "    img[:,:,0] = np.clip(img[:,:,0] + blue_diff, 0, 255)\n",
    "    variable = name\n",
    "    filename = f'balanced_{variable}'\n",
    "\n",
    "    \n",
    "    # Get the base name of the image file without the extension\n",
    "    base_name = os.path.splitext(variable)[0]\n",
    "    \n",
    "    # Create a directory with the base name of the image inside the \"images\" directory if it doesn't exist\n",
    "    directory = os.path.join('images', base_name)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # Create the filename for the balanced image\n",
    "    filename = os.path.join(directory, f'balanced_{variable}')\n",
    "    \n",
    "    # Save the image\n",
    "    cv2.imwrite(filename, img)\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def estimate_background_light_for_each_channel(image):\n",
    "    # Initialize background light for each channel\n",
    "    background_light_channels = np.zeros(3)\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray_image = image\n",
    "    \n",
    "    # Initialize threshold for quadtree division\n",
    "    threshold = gray_image.size * 0.001\n",
    "    \n",
    "    # Define function for quadtree division\n",
    "    def quadtree_division(image, threshold):\n",
    "        variance = np.var(image)\n",
    "        \n",
    "        # If variance is less than threshold, return mean intensity as background light\n",
    "        if variance < threshold:\n",
    "            return np.mean(image)\n",
    "        \n",
    "        # Otherwise, divide image into four quadrants\n",
    "        height, width = image.shape\n",
    "        half_height, half_width = height // 2, width // 2\n",
    "        quadrants = [\n",
    "            image[:half_height, :half_width],\n",
    "            image[:half_height, half_width:],\n",
    "            image[half_height:, :half_width],\n",
    "            image[half_height:, half_width:]\n",
    "        ]\n",
    "        \n",
    "        # Recursively call quadtree_division on each quadrant\n",
    "        background_lights = [quadtree_division(quadrant, threshold) for quadrant in quadrants]\n",
    "        \n",
    "        # Return the minimum background light among quadrants\n",
    "        return min(background_lights)\n",
    "    \n",
    "    # Start quadtree division for each channel\n",
    "    for i in range(3):  # Assuming BGR image\n",
    "        background_light_channels[i] = quadtree_division(image[:,:,i], threshold)\n",
    "    print(\"Estimated Background Light for Each Channel:\", background_light_channels)\n",
    "    return background_light_channels\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_contrast_and_complex_performance_index(I, t):\n",
    "    \n",
    "    # Calculate the number of channels\n",
    "    num_channels = I.shape[2]\n",
    "    \n",
    "    # Initialize arrays to store contrast values Ci for each channel\n",
    "    Ci = np.zeros(num_channels)\n",
    "    \n",
    "    # Loop through each color channel\n",
    "    for i in range(num_channels):\n",
    "       \n",
    "        # Calculate the contrast value Ci for the current channel\n",
    "        squared_diff_channel = (I[:,:,i] - np.mean(I[:,:,i])) ** 2\n",
    "        Ci[i] = np.sum(squared_diff_channel / (t ** 2 * I.size))\n",
    "    \n",
    "    # Calculate the complex contrast performance index Ec\n",
    "    Ec = -np.sum(Ci)\n",
    "    \n",
    "    return Ci, Ec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_information_loss_El(I, A, t):\n",
    "    # Initialize J(x) array\n",
    "    J = np.zeros_like(I)\n",
    "    \n",
    "    # Calculate J(x) using the restoration model equation for each channel\n",
    "    for i in range(3):  # Assuming RGB image\n",
    "\n",
    "        J[:,:,i] = (1 / t) * (I[:,:,i] - A[i]) + A[i]\n",
    "    \n",
    "    # Ensure J is within the allowable range (0 to 255)\n",
    "    J_clipped = np.clip(J, 0, 255)\n",
    "    \n",
    "    # Calculate information loss function El\n",
    "    El = 0\n",
    "    \n",
    "    # Loop through each color channel\n",
    "    for i in range(3):  # Assuming RGB image\n",
    "        # Calculate information loss for each pixel in the channel\n",
    "        loss_channel = (np.minimum(0, J_clipped[:,:,i])**2) + np.maximum(0, J_clipped[:,:,i] - 255)\n",
    "        \n",
    "        # Sum up the information loss for the channel\n",
    "        El += np.sum(loss_channel)\n",
    "    \n",
    "    return El\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def combined_objective_function(Ec, El, lambda_L):\n",
    "    # Calculate the combined objective function\n",
    "    return Ec + lambda_L * El\n",
    "\n",
    "def optimize_transmittance(I, A, lambda_L, initial_guesses):\n",
    "    # Initialize lists to store results\n",
    "    optimal_t = []\n",
    "    optimal_Ec = []\n",
    "    optimal_El = []\n",
    "    optimal_E = []\n",
    "    print(len(initial_guesses),\"kk\")\n",
    "    # Loop through each initial guess for t\n",
    "    for i, initial_guess in enumerate(initial_guesses):\n",
    "       \n",
    "\n",
    "       \n",
    "            # Calculate contrast value Ci and complex contrast performance index Ec\n",
    "        Ci, Ec = calculate_contrast_and_complex_performance_index(I, initial_guess)\n",
    "    \n",
    "            # Calculate information loss El\n",
    "        El = calculate_information_loss_El(I, A, initial_guess)\n",
    "            \n",
    "            # Calculate combined objective function E\n",
    "        E = combined_objective_function(Ec, El, lambda_L)\n",
    "            \n",
    "            # Store results\n",
    "        \n",
    "                \n",
    "        \n",
    "        \n",
    "        # Store the results for this initial guess\n",
    "        optimal_t.append(initial_guess)\n",
    "        optimal_Ec.append(Ec)\n",
    "        optimal_El.append(El)\n",
    "        optimal_E.append(E)\n",
    "    \n",
    "    # Find the index corresponding to the minimum value of E among all initial guesses\n",
    "    best_index = np.argmin(optimal_E)\n",
    "    \n",
    "    # Return the best results\n",
    "    return optimal_t[best_index], optimal_Ec[best_index], optimal_El[best_index], optimal_E[best_index]\n",
    "\n",
    "# Example usage:\n",
    "# Read RGB image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def restore_image(I, A, t,name):\n",
    "    # Initialize the restored image\n",
    "    restored_image = np.zeros_like(I)\n",
    "\n",
    "    # Iterate over each pixel in the image\n",
    "    for i in range(I.shape[0]):\n",
    "        for j in range(I.shape[1]):\n",
    "            # Apply the restoration model formula for each channel\n",
    "            for k in range(3):  # Iterate over R, G, B channels\n",
    "                restored_image[i, j, k] = (1 / t[i, j]) * (I[i, j, k] - A[k]) + A[k]\n",
    "  \n",
    "\n",
    "    # Get the base name of the image file without the extension\n",
    "    base_name = os.path.splitext(name)[0]\n",
    "\n",
    "    # Create a directory with the base name of the image inside the \"images\" directory if it doesn't exist\n",
    "    directory = os.path.join('images', base_name)\n",
    "    \n",
    "\n",
    "    # Create the filename for the restored image\n",
    "    restored_name = os.path.join(directory, f'restored_{name}.jpg')\n",
    "\n",
    "    # Save the image\n",
    "    cv2.imwrite(restored_name, restored_image)\n",
    "    return restored_image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_average_red_channel_value(image):\n",
    "    # Assuming 'image' is a 3D NumPy array representing the image (height x width x channels)\n",
    "    red_channel = image[:, :, 0]  # Assuming red channel is the first channel (index 0)\n",
    "    average_red_value = np.mean(red_channel)\n",
    "    print(\"Average Red Channel Value:\", average_red_value)\n",
    "    return average_red_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_histogram_threshold(image):\n",
    "    # Calculate total number of pixels\n",
    "    height, width, _ = image.shape\n",
    "    total_pixels = height * width\n",
    "    print(total_pixels)\n",
    "    # Calculate histogram threshold (h1) as n*0.225%\n",
    "    histogram_threshold = total_pixels * 0.00225\n",
    "    print(\"Histogram Threshold:\", histogram_threshold)\n",
    "    return  histogram_threshold\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def histogram_stretching(image, R_ave, R_threshold,name):\n",
    "    # Calculate total number of pixels\n",
    "    height, width, _ = image.shape\n",
    "    total_pixels = height * width\n",
    "    \n",
    "    # Determine if attenuation of red light is slight or heavy\n",
    "    if R_ave >= R_threshold:  # Slight attenuation\n",
    "        channels = [0, 1, 2]  # Stretching for all channels (R, G, B)\n",
    "    else:  # Heavy attenuation\n",
    "        channels = [1, 2]  # Stretching for G, B channels only\n",
    "    \n",
    "    # Calculate satisfactory threshold ht as n * 0.225%\n",
    "    ht = total_pixels * 0.00225\n",
    "    \n",
    "    # Calculate minimal and maximal scalar values based on ht\n",
    "    imin = 0\n",
    "    imax = 255\n",
    "    \n",
    "    # If ht is provided and it's greater than zero, update imin and imax\n",
    "    if ht > 0:\n",
    "        # Calculate lower and upper thresholds based on ht\n",
    "        imin = np.min(image)\n",
    "        imax = np.max(image)\n",
    "        lower_threshold_count = int(ht)\n",
    "        upper_threshold_count = int(total_pixels - ht)\n",
    "        sorted_pixels = np.sort(image.flatten())\n",
    "        imin = sorted_pixels[lower_threshold_count]\n",
    "        imax = sorted_pixels[upper_threshold_count]\n",
    "\n",
    "    # Apply histogram stretching to selected channels\n",
    "    stretched_image = image.copy()\n",
    "    for channel in channels:\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                old_value = stretched_image[i, j, channel]\n",
    "                if old_value < imin:\n",
    "                    stretched_image[i, j, channel] = 0\n",
    "                elif old_value > imax:\n",
    "                    stretched_image[i, j, channel] = 255\n",
    "                else:\n",
    "                    stretched_image[i, j, channel] = 255 * (old_value - imin) / (imax - imin)\n",
    "    base_name = os.path.splitext(name)[0]\n",
    "\n",
    "    # Create a directory with the base name of the image inside the \"images\" directory if it doesn't exist\n",
    "    directory = os.path.join('images', base_name)\n",
    "    \n",
    "\n",
    "    # Create the filename for the restored image\n",
    "    stretched_name = os.path.join(directory, f'strectched_{name}.jpg')\n",
    "    cv2.imwrite(stretched_name, stretched_image)\n",
    "    return stretched_image\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage import color\n",
    "\n",
    "def calculate_rms_contrast(image):\n",
    "    \"\"\"\n",
    "    Calculate the Root Mean Square (RMS) contrast of an image.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean(np.square(image - np.mean(image))))\n",
    "\n",
    "def calculate_uciqe(image):\n",
    "    \"\"\"\n",
    "    Calculate the Underwater Color Image Quality Evaluation (UCIQE) of an image.\n",
    "    \"\"\"\n",
    "    c1 = 0.4680\n",
    "    c2 = 0.2745\n",
    "    c3 = 0.2576\n",
    "    img_yuv = color.rgb2yuv(image)\n",
    "    y = img_yuv[:,:,0]\n",
    "    u = img_yuv[:,:,1]\n",
    "    v = img_yuv[:,:,2]\n",
    "    uciqe = c1 * np.std(y) / np.mean(y) + c2 * np.cov(u, v) / (np.std(u) * np.std(v)) + c3 * np.mean(v)\n",
    "    return uciqe\n",
    "\n",
    "def calculate_psnr(image_true, image_test):\n",
    "    \"\"\"\n",
    "    Calculate the Peak Signal-to-Noise Ratio (PSNR) between two images.\n",
    "    \"\"\"\n",
    "    return psnr(image_true, image_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def process_image(name):\n",
    "    img = cv2.imread(name)\n",
    "    # Apply color balance\n",
    "    balanced_img = color_balance(img,name)\n",
    "    # Estimate background light for each channel\n",
    "    background_light_channels = estimate_background_light_for_each_channel(balanced_img)\n",
    "    # Background light A obtained from Step 1 (assuming some value)\n",
    "    A = background_light_channels\n",
    "    # Tradeoff factor\n",
    "    lambda_L = 5\n",
    "    # Initial guesses for transmittance\n",
    "    constant = 0.1  # or any small value you prefer\n",
    "    initial_guesses = [np.around(np.clip(np.random.rand(*balanced_img.shape[:2]) + constant, constant,1), decimals=2) for _ in range(10)]\n",
    "    # Optimize transmittance\n",
    "    t_optimal, Ec_optimal, El_optimal, E_optimal = optimize_transmittance(balanced_img, A, lambda_L,initial_guesses )\n",
    "    # Restore the image using the restoration model and the calculated transmittance map\n",
    "    restored_image = restore_image(balanced_img, A, t_optimal,name)\n",
    "    average_red = calculate_average_red_channel_value(restored_image)\n",
    "    histogram_threshold = calculate_histogram_threshold(restored_image)\n",
    "    r,_,_ = cv2.split(restored_image)\n",
    "    retval, thresholded_image = cv2.threshold(r, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    average_thresholded = np.mean(thresholded_image)\n",
    "    print(average_thresholded,\"d\")\n",
    "    # Apply histogram stretching\n",
    "    stretched_image = histogram_stretching(restored_image, average_red, average_thresholded,name)\n",
    "    # Calculate metrics\n",
    "    rms_contrast1 = calculate_rms_contrast(img)\n",
    "    rms_contrast2 = calculate_rms_contrast(stretched_image)\n",
    "    uciqe1 = calculate_uciqe(img)\n",
    "    uciqe2 = calculate_uciqe(stretched_image)\n",
    "    psnr_value = calculate_psnr(img, stretched_image)\n",
    "    return rms_contrast1, rms_contrast2, uciqe1, uciqe2, psnr_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Background Light for Each Channel: [107.205025   107.27166667 107.2474    ]\n",
      "10 kk\n",
      "Average Red Channel Value: 109.47844166666667\n",
      "120000\n",
      "Histogram Threshold: 270.0\n",
      "65.53925 d\n",
      "Estimated Background Light for Each Channel: [ 85.07306667  55.10105263 134.01956667]\n",
      "10 kk\n",
      "Average Red Channel Value: 136.05645\n",
      "120000\n",
      "Histogram Threshold: 270.0\n",
      "133.974875 d\n",
      "Estimated Background Light for Each Channel: [ 74.1044      72.51533333 124.14475833]\n",
      "10 kk\n",
      "Average Red Channel Value: 132.21738333333334\n",
      "120000\n",
      "Histogram Threshold: 270.0\n",
      "127.106875 d\n",
      "Estimated Background Light for Each Channel: [123.09353333 105.51933333 122.89369167]\n",
      "10 kk\n",
      "Average Red Channel Value: 125.13618333333334\n",
      "120000\n",
      "Histogram Threshold: 270.0\n",
      "129.877875 d\n",
      "Estimated Background Light for Each Channel: [123.69449167  72.60631579 123.66061667]\n",
      "10 kk\n",
      "Average Red Channel Value: 127.595975\n",
      "120000\n",
      "Histogram Threshold: 270.0\n",
      "165.99225 d\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (name, rms_contrast1, rms_contrast2, uciqe1, uciqe2, psnr_value)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Process the images sequentially\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m results \u001b[38;5;241m=\u001b[39m [\u001b[43mprocess_and_collect_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m image_names]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Unpack the results into separate lists\u001b[39;00m\n\u001b[0;32m     13\u001b[0m image_names, rms_contrast1_list, rms_contrast2_list, uciqe1_list, uciqe2_list, psnr_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults)\n",
      "Cell \u001b[1;32mIn[42], line 6\u001b[0m, in \u001b[0;36mprocess_and_collect_metrics\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_and_collect_metrics\u001b[39m(name):\n\u001b[1;32m----> 6\u001b[0m     rms_contrast1, rms_contrast2, uciqe1, uciqe2, psnr_value \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (name, rms_contrast1, rms_contrast2, uciqe1, uciqe2, psnr_value)\n",
      "Cell \u001b[1;32mIn[38], line 8\u001b[0m, in \u001b[0;36mprocess_image\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m      6\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(name)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Apply color balance\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m balanced_img \u001b[38;5;241m=\u001b[39m \u001b[43mcolor_balance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Estimate background light for each channel\u001b[39;00m\n\u001b[0;32m     10\u001b[0m background_light_channels \u001b[38;5;241m=\u001b[39m estimate_background_light_for_each_channel(balanced_img)\n",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m, in \u001b[0;36mcolor_balance\u001b[1;34m(img, name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcolor_balance\u001b[39m(img,name):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# 1. Calculate the average intensity of each color channel\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     red_avg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mimg\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      4\u001b[0m     green_avg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(img[:,:,\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      5\u001b[0m     blue_avg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(img[:,:,\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# List of image names\n",
    "image_names = [\"1.jpg\", \"2.jpg\",  \"6.jpg\", \"7.jpg\", \"8.jpg\",  \"10.jpg\"]\n",
    "\n",
    "# Function to process image and return a tuple with all metrics\n",
    "def process_and_collect_metrics(name):\n",
    "    rms_contrast1, rms_contrast2, uciqe1, uciqe2, psnr_value = process_image(name)\n",
    "    return (name, rms_contrast1, rms_contrast2, uciqe1, uciqe2, psnr_value)\n",
    "\n",
    "# Process the images sequentially\n",
    "results = [process_and_collect_metrics(name) for name in image_names]\n",
    "\n",
    "# Unpack the results into separate lists\n",
    "image_names, rms_contrast1_list, rms_contrast2_list, uciqe1_list, uciqe2_list, psnr_list = zip(*results)\n",
    "\n",
    "# Create a DataFrame for each metric\n",
    "rms_contrast_df = pd.DataFrame({'Image': image_names, 'RMS Contrast (Base Image)': rms_contrast1_list, 'RMS Contrast (Final Image)': rms_contrast2_list})\n",
    "uciqe_df = pd.DataFrame({'Image': image_names, 'UCIQE (Base Image)': uciqe1_list, 'UCIQE (Final Image)': uciqe2_list})\n",
    "psnr_df = pd.DataFrame({'Image': image_names, 'PSNR': psnr_list})\n",
    "\n",
    "# Print the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_contrast_df.to_csv('rms_contrast.csv', index=False)\n",
    "rms_contrast_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uciqe_df.to_csv('uciqe.csv', index=False)\n",
    "\n",
    "uciqe_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr_df.to_csv('psnr.csv', index=False)\n",
    "psnr_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
